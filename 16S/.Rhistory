dim(taxonomy)
#read the metadata
map <- read.csv("bean.var.map.csv")
#select only biological sample from otu table
otu.bac <- otu[,1:47] #unselect Mock, NC, and PC from the otu table
dim(otu.bac)
sort(rowSums(otu.bac, na.rm = FALSE, dims = 1), decreasing = F)
# remove OTUs that do not present in sample
otu.bac1=otu.bac[which(rowSums(otu.bac) > 0),]
dim(otu.bac1) # otu= 229, otu table before normalization using metagenomeSeq package and before decontamination
sort(rowSums(otu.bac1, na.rm = FALSE, dims = 1), decreasing = F)
# merge otu.bac1 with taxonomy to have match taxonomy table
head(otu.bac1)
otu.bac1 <- rownames_to_column(otu.bac1,var = "OTU.ID")
taxonomy <- rownames_to_column(taxonomy,var = "OTU.ID")
otu.bac1.tax <- merge(otu.bac1, taxonomy, by="OTU.ID")
library(multcomp)
library(car)
library(BiocManager)
library(vegan)
library(plyr)
library(dplyr)
library(tidyverse)
library(tidyr)
#library(cowplot)
library(ggplot2)
library(reshape)
library(ggpubr)
library(car)
library(agricolae)
library(multcompView)
library(grid)
library(gridExtra)
library(sjmisc)
library(sjPlot)
library(MASS)
library(FSA)
library(rcompanion)
library(onewaytests)
library(ggsignif)
library(PerformanceAnalytics)
library(gvlma)
library(userfriendlyscience)
library(ggpmisc)
install.packages("userfriendlyscience")
library(ggpmisc)
library(tibble)
library(fitdistrplus)
library(lme4)
library(nlme)
# SET THE WORKING DIRECTORY
setwd('/Users/arifinabintarti/Documents/GitHub/Bean_seed_variability_Bintarti_2021/16S')
wd <- print(getwd())
otu <- read.table('OTU_table_tax_filt.txt', sep='\t', header=T, row.names = 1)
otu
tax <- otu[,'taxonomy']
str(tax)
#write.csv(tax, file = "taxonomy.csv")
dim(otu)
otu <- otu[,-51]
dim(otu) # otu= 273, otu table still has Mock, NC, and PC in the sample
sort(rowSums(otu, na.rm = FALSE, dims = 1), decreasing = F)
#read taxonomy
taxonomy = read.csv("taxonomy.edit.csv", header=T)
rownames(taxonomy) <- rownames(otu)
dim(taxonomy)
#read the metadata
map <- read.csv("bean.var.map.csv")
#select only biological sample from otu table
otu.bac <- otu[,1:47] #unselect Mock, NC, and PC from the otu table
dim(otu.bac)
sort(rowSums(otu.bac, na.rm = FALSE, dims = 1), decreasing = F)
# remove OTUs that do not present in sample
otu.bac1=otu.bac[which(rowSums(otu.bac) > 0),]
dim(otu.bac1) # otu= 229, otu table before normalization using metagenomeSeq package and before decontamination
sort(rowSums(otu.bac1, na.rm = FALSE, dims = 1), decreasing = F)
# merge otu.bac1 with taxonomy to have match taxonomy table
head(otu.bac1)
otu.bac1 <- rownames_to_column(otu.bac1,var = "OTU.ID")
taxonomy <- rownames_to_column(taxonomy,var = "OTU.ID")
otu.bac1.tax <- merge(otu.bac1, taxonomy, by="OTU.ID")
dim(otu.bac1.tax)
#  separate  the otu table
#otu table
otu.bac.plantfil <- data.frame(otu.bac1.tax[,c(1:48)])
head(otu.bac.plantfil)
otu.bac.plantfil <- column_to_rownames(otu.bac.plantfil,var="OTU.ID")
sum(otu.bac.plantfil)
#otu table of the negative control
otu.NC <- otu[,"NC",drop=FALSE]#only negative control
otu.NC
#install and load microDecon package
#install.packages("devtools")
#devtools::install_github("donaldtmcknight/microDecon")
library(microDecon)
#merge otu.NC to otu bac and put otu.NC as the first column
head(otu.NC)
otu.NC <- rownames_to_column(otu.NC, var = "OTU.ID")
head(otu.bac1)
#otu.bac1 <- rownames_to_column(otu.bac1, var = "OTU.ID")
otu.NC.bac <- merge(otu.NC, otu.bac1, by="OTU.ID")
dim(otu.NC.bac)
#decontamination
otu.decon <- decon(data = otu.NC.bac, numb.blanks = 1, numb.ind = 47, taxa = F)
otu.decon$OTUs.removed # remove 18 OTUs
otu.tab <- as.data.frame(otu.decon$decon.table)
dim(otu.tab) #there are 211 otus and 47 samples
#remove NC from the otu.dec.table
otu.tab <- otu.tab[,c(1,3:49)]
#merge otu.dec.table with taxonomy to have match taxonomy table
head(taxonomy)
head(otu.tab)
#taxonomy <- rownames_to_column(taxonomy, var = "OTU.ID")
otu.tab.tax <- merge(otu.tab, taxonomy, by = "OTU.ID")
otu.tab.tax
#separate the otu table and taxonomy table
#otu table
decon.otu <- data.frame(otu.tab.tax[,c(1:48)])
dim(decon.otu) #211 otus, 47samples
tax <- data.frame(otu.tab.tax[,c(1,49:55)], row.names = 1)
dim(tax) #211 otus, 7columns/levels
head(decon.otu)
decon.otu <- column_to_rownames(decon.otu, var = "OTU.ID")
sort(colSums(decon.otu, na.rm = FALSE, dims = 1), decreasing = F)
sort(rowSums(decon.otu, na.rm = FALSE, dims = 1), decreasing = F)
#install and load metagenomeSeq package
#BiocManager::install("metagenomeSeq", dependencies=TRUE)
library(metagenomeSeq)
#loading count data (otu)
decon.otu
#loading metadata
map <- read.csv("bean.var.map.csv")
head(map)
dim(map)
map <- column_to_rownames(map, var="Sample.id")
View(map)
phenotypeData <- AnnotatedDataFrame(map)
phenotypeData
#loading taxonomy
head(tax)
OTUdata <- AnnotatedDataFrame(tax)
OTUdata
#Creating a MRexperiment object
model <- newMRexperiment(decon.otu, phenoData = phenotypeData, featureData = OTUdata)
model
sort(rowSums(MRcounts(model), na.rm = FALSE, dims = 1), decreasing = T)
# 1. calculate the proper percentile by which to normalize counts
p <- cumNormStatFast(model, pFlag = T)
p
# 2. To calculate the scaling factors we simply run cumNorm
#cumNorm=Calculates each columnâ€™s quantile and calculates the sum up to and including that quantile.
bac.norm <- cumNorm(model, p = p)
bac.norm
# 3. Exporting normalized count matrix
otu.norm <- MRcounts(bac.norm, norm = TRUE, log = F)
otu.norm <- as.data.frame(otu.norm)
head(sort(colSums(otu.norm, na.rm = FALSE, dims = 1), decreasing = FALSE))
head(sort(rowSums(otu.norm, na.rm = FALSE, dims = 1), decreasing = FALSE))
head(otu.norm)
otu.norm <- rownames_to_column(otu.norm, var="OTU.ID")
#write.table(otu.norm, "otu_norm.txt", sep = "\t", quote = F, row.names = F)
dim(otu.norm) #there are 211 otus and 47 samples
library(phyloseq)
# make phyloseq map
bean.map <- map
head(bean.map)
bean.map <- rownames_to_column(bean.map, var = "Sample.id")
bean.map$Plant <- as.factor(bean.map$Plant)
bean.map$Sample.id <- as.factor(bean.map$Sample.id)
head(bean.map)
rownames(bean.map) <- bean.map$Sample.id
map.phyl <- sample_data(bean.map)
# load normalized otu table
otu.norm
head(otu.norm)
otu.norm <- column_to_rownames(otu.norm, var = "OTU.ID")
# bacterial taxonomy
head(tax)
#tax <- column_to_rownames(tax, var = "OTU.ID")
rownames(tax) <- rownames(otu.norm)
# make phyloseq otu table and taxonomy
otu.phyl = otu_table(otu.norm, taxa_are_rows = TRUE)
tax.phyl = tax_table(as.matrix(tax))
# make phyloseq map
rownames(bean.map) <- bean.map$Sample.id
map.phyl <- sample_data(bean.map)
phyl.obj <- merge_phyloseq(otu.phyl,tax.phyl,map.phyl)
phyl.obj
setwd('/Users/arifinabintarti/Documents/GitHub/Bean_seed_variability_Bintarti_2021/16S')
wd <- print(getwd())
# calculate richness
head(otu.norm)
#otu.norm <- column_to_rownames(otu.norm, var="OTU.ID")
s <- specnumber(otu.norm, MARGIN = 2) # richness
rich <- as.data.frame(s)
bean.map <- map
dim(bean.map)
bean.map$Richness <- s
bean.map
#add Faith's PD index
pd.index <- read.table('PD.txt', sep='\t', header=T, row.names = 1)
pd.index <- rownames_to_column(pd.index, "Sample.id")
#join Faith's PD index to the map
bean.map <- rownames_to_column(bean.map, var = "Sample.id")
bean.map <- merge(bean.map, pd.index, by="Sample.id", all = T)
View(bean.map)
write.csv(bean.map, file = "bean.map.csv")
#load the  data
setwd('/Users/arifinabintarti/Documents/GitHub/Bean_seed_variability_Bintarti_2021/16S')
wd <- print(getwd())
bean.map <- read.csv("bean.map.csv")
View(bean.map)
bean.map <- read.csv("bean.map.csv", row.names = 1)
data.rich <- bean.map[,c(2,6,7)]
View(data.rich)
#calculate mean and sd of richness and PD
data.bac <- bean.map %>%
summarise(mean.rich = mean(Richness),
mean.pd = mean(PD_whole_tree),
sd.rich = sd(Richness),
sd.pd = sd(PD_whole_tree))
View(data.bac)
#group by plant
data.bac.plant <- bean.map %>%
group_by(Plant) %>%
summarise(mean.rich = mean(Richness),
sd.rich = sd(Richness),
var.rich = var(Richness),
mean.pd = mean(PD_whole_tree),
sd.pd = sd(PD_whole_tree),
var.pd = var(PD_whole_tree))
data.bac.plant
View(data.bac.plant)
#group by plant
data.bac.plant <- bean.map %>%
group_by(Plant) %>%
summarise(mean.rich = mean(Richness),
sd.rich = sd(Richness),
var.rich = var(Richness),
mean.pd = mean(PD_whole_tree),
sd.pd = sd(PD_whole_tree),
var.pd = var(PD_whole_tree))
data.bac.plant
#group by plant
detach(package:plyr)
data.bac.plant <- bean.map %>%
group_by(Plant) %>%
summarise(mean.rich = mean(Richness),
sd.rich = sd(Richness),
var.rich = var(Richness),
mean.pd = mean(PD_whole_tree),
sd.pd = sd(PD_whole_tree),
var.pd = var(PD_whole_tree))
data.bac.plant
#plant A
n1 <- 12
mean.rich.a <- 30.58
sd.rich.a <- 6.41
#plant B
n2 <- 24
mean.rich.b <- 18.20
sd.rich.b <- 7.35
#add size to the data frame
data.bac.plant$Size <- c(12,24,11)
View(data.bac.plant)
library(utilities)
# Calculating effect size (Cohen's d) using the max and min means out of the 3 groups using linear model
group <- 3
data.bac.plant
fit.rich <- lm(Richness~Plant, data = bean.map)
anova(fit.rich)
# Error or within-group variance or Means Squared Error
anova(fit.rich)["Residuals", "Mean Sq"] #[1] 65.85873 or MSE
d=((30.58333-18.20833))/(sqrt(65.85873))
d # 1.52489
(30.58333-18.20833)/8.114
# sqrt(MSE)  OR RMSE also can be calculated  below:
sqrt(sum(fit.rich$residuals^2) / fit.rich$df)
# corrected Cohen's  (Hedges's g)
g = d * (1-(3/((4*36)-9)))
g
# simulation
n <- seq(0, 100, 1)
n
power <- sapply(seq_along(n), function(i)
power.t.test(n = n[i], delta =g, sig.level = 0.05, type = 'two.sample')$power)
power
power.df <- data.frame(n=n, power=power)
power.rich.plot <- ggplot(power.df, aes(x=n, y=power))+
geom_line(size=1.5)+
#geom_hline(yintercept = 0.8, linetype = 2, color = "gray30")+
geom_hline(yintercept = 0.8, linetype = 2, color = "gray30")+
geom_vline(xintercept = 10, linetype = 2, color = "gray30")+
scale_x_continuous("Sample Size", breaks = seq(0,100, 20))+
scale_y_continuous("Power", breaks = seq(0,1,.2))+
labs(title="(a)")+
expand_limits(x = 0, y = 0)+
theme_bw(base_size = 14)+
theme(axis.text = element_text(size = 14),
axis.title.x = element_blank(),
strip.text = element_text(size=18, face = 'bold'),
plot.title = element_text(size = 20,face = 'bold'),
axis.title.y = element_text(size=15,face="bold"))
power.rich.plot
pwr.t.test(d=g,power=.95,sig.level=.05,type="two.sample")
#plant A
n1 <- 12
mean.pd.a <- 4.17
sd.pd.a <- 0.88
#plant B
n2 <- 24
mean.pd.b <- 2.92
sd.pd.b <- 0.82
data.bac.plant$Size <- c(12,24,11)
fit.pd <- lm(PD_whole_tree~Plant, data = bean.map)
anova(fit.pd)
# Error or within-group variance or Means Squared Error
anova(fit.pd)["Residuals", "Mean Sq"] #[1] 0.9937546 or MSE
d.pd=((4.174887-2.924510))/(sqrt(0.9937546))
d.pd # 1.2543
# corrected Cohen's  (Hedges's g)
g.pd = d.pd * (1-(3/((4*36)-9)))
g.pd
n <- seq(0, 100, 1)
n
power.pd <- sapply(seq_along(n), function(i)
power.t.test(n = n[i], delta =g.pd, sig.level = 0.05, type = 'two.sample')$power)
power.pd
power.pd.df <- data.frame(n=n, power=power.pd)
power.pd.plot <- ggplot(power.pd.df, aes(x=n, y=power))+
geom_line(size=1.5)+
geom_hline(yintercept = 0.8, linetype = 2, color = "gray30")+
geom_vline(xintercept = 10, linetype = 2, color = "gray30")+
scale_x_continuous("Sample Size", breaks = seq(0,100, 20))+
scale_y_continuous("Power", breaks = seq(0,1,.2))+
expand_limits(x = 0, y = 0)+
#scale_x_discrete(labels= label)+
labs(title="(b)")+
theme_bw(base_size = 14)+
theme(axis.text.y = element_blank(),
axis.ticks.y = element_blank(),
axis.title = element_blank(),
axis.text.x = element_text(size = 14),
strip.text = element_text(size=18, face = 'bold'),
plot.title = element_text(size = 20,face = 'bold'))
#axis.title = element_text(size=15,face="bold"))
power.pd.plot
pwr.t.test(d=g.pd,power=.8,sig.level=.05,type="two.sample")
pwr.t.test(d=g.pd,power=.95,sig.level=.05,type="two.sample")
effect_sizes <- c(.25, .5, .8)
conditions <- expand.grid(n = n, effect_sizes = effect_sizes)
power_curve <- sapply(seq_len(nrow(conditions)), function(i)
power.t.test(n = conditions[i, 'n'],
delta =  conditions[i, 'effect_sizes'],
type = 'two.sample')$power)
power_curve
power_curve_df <- bind_cols( conditions,power = power_curve)
ggplot(power_curve_df, aes(x = n, y = power)) +
geom_line(aes(color = factor(effect_sizes)), size = 2) +
geom_hline(yintercept = 0.8, linetype = 2, color = 'gray30') +
scale_x_continuous("Sample Size", breaks = seq(0, 100, 20)) +
scale_y_continuous("Power", breaks = seq(0, 1, .2)) +
scale_color_grey("Effect Size") +
theme_bw(base_size = 14)
groupmeans <- data.bac.plant$mean.rich
p.rich <- power.anova.test(groups = length(groupmeans),
between.var = var(groupmeans), within.var = 65.85873 ,
power=0.95,sig.level=0.05,n=NULL)
p.rich
groupmeans <- data.bac.plant$mean.rich
n.aov <- c(seq(2,10,by=1),seq(12,20,by=2),seq(25,50,by=5))
p.rich <- power.anova.test(groups = length(groupmeans),
between.var = var(groupmeans), within.var = 65.85873,
power=NULL, sig.level=0.05,n=n.aov)
p.rich
p.rich.df <- data.frame(n=n, power=power)
plot(n.aov,p.rich$power)
library(DescTools)
set.seed(13)
nested.rich <- aov(bean.map$Richness~bean.map$Plant/factor(bean.map$Pod))
EtaSq(nested.rich, type=1, anova=TRUE)
EtaSq(fit.rich, type=1, anova=TRUE)
set.seed(13)
pwr.anova.test(k = 2, f =0.719, sig.level =0.05 , power =0.8 )
pwr.anova.test(k = 2, f =0.719, sig.level =0.05 , power =0.95 )
power <- sapply(seq_along(n), function(i)
power.t.test(n = n[i], delta =g, sig.level = 0.05, type = 'two.sample')$power)
power
g
# Error or within-group variance or Means Squared Error
anova(fit.rich)["Residuals", "Mean Sq"] #[1] 65.85873 or MSE
power.df <- data.frame(n=n, power=power)
View(power.df)
power.rich.plot <- ggplot(power.df, aes(x=n, y=power))+
geom_line(size=1.5)+
#geom_hline(yintercept = 0.8, linetype = 2, color = "gray30")+
geom_hline(yintercept = 0.8, linetype = 2, color = "gray30")+
geom_vline(xintercept = 10, linetype = 2, color = "gray30")+
scale_x_continuous("Sample Size", breaks = seq(0,100, 20))+
scale_y_continuous("Power", breaks = seq(0,1,.2))+
labs(title="(a)")+
expand_limits(x = 0, y = 0)+
theme_bw(base_size = 14)+
theme(axis.text = element_text(size = 14),
axis.title.x = element_blank(),
strip.text = element_text(size=18, face = 'bold'),
plot.title = element_text(size = 20,face = 'bold'),
axis.title.y = element_text(size=15,face="bold"))
power.rich.plot
pwr.t.test(d=g,power=.95,sig.level=.05,type="two.sample")
pwr.t.test(d=g,power=.8,sig.level=.05,type="two.sample")
pwr.t.test(d=g,power=.95,sig.level=.05,type="two.sample")
pwr.t.test(d=g.pd,power=.8,sig.level=.05,type="two.sample")
pwr.t.test(d=g.pd,power=.95,sig.level=.05,type="two.sample")
effect_sizes <- c(.25, .5, .8)
conditions <- expand.grid(n = n, effect_sizes = effect_sizes)
power_curve <- sapply(seq_len(nrow(conditions)), function(i)
power.t.test(n = conditions[i, 'n'],
delta =  conditions[i, 'effect_sizes'],
type = 'two.sample')$power)
power_curve
power_curve
power_curve_df <- bind_cols( conditions,power = power_curve)
ggplot(power_curve_df, aes(x = n, y = power)) +
geom_line(aes(color = factor(effect_sizes)), size = 2) +
geom_hline(yintercept = 0.8, linetype = 2, color = 'gray30') +
scale_x_continuous("Sample Size", breaks = seq(0, 100, 20)) +
scale_y_continuous("Power", breaks = seq(0, 1, .2)) +
scale_color_grey("Effect Size") +
theme_bw(base_size = 14)
pwr.t.test(d=g.pd,power=.8,sig.level=.05,type="two.sample")
pwr.t.test(d=g.pd,power=.95,sig.level=.05,type="two.sample")
#power_curve_df <- bind_cols( conditions,power = power_curve)
ggplot(power_curve_df, aes(x = n, y = power)) +
geom_line(aes(color = factor(effect_sizes)), size = 2) +
geom_hline(yintercept = 0.8, linetype = 2, color = 'gray30') +
scale_x_continuous("Sample Size", breaks = seq(0, 100, 20)) +
scale_y_continuous("Power", breaks = seq(0, 1, .2)) +
scale_color_grey("Effect Size") +
theme_bw(base_size = 14)
groupmeans <- data.bac.plant$mean.rich
p.rich <- power.anova.test(groups = length(groupmeans),
between.var = var(groupmeans), within.var = 65.85873 ,
power=0.95,sig.level=0.05,n=NULL)
p.rich
groupmeans <- data.bac.plant$mean.rich
n.aov <- c(seq(2,10,by=1),seq(12,20,by=2),seq(25,50,by=5))
p.rich <- power.anova.test(groups = length(groupmeans),
between.var = var(groupmeans), within.var = 65.85873,
power=NULL, sig.level=0.05,n=n.aov)
p.rich
p.rich.df <- data.frame(n=n, power=power)
plot(n.aov,p.rich$power)
set.seed(13)
pwr.anova.test(k = 2, f =0.719, sig.level =0.05 , power =0.8 )
pwr.anova.test(k = 2, f =0.719, sig.level =0.05 , power =0.95 )
pwr.t.test(d=g.pd,power=.8,sig.level=.05,type="two.sample")
pwr.t.test(d=g.pd,power=.95,sig.level=.05,type="two.sample")
groupmeans <- data.bac.plant$mean.rich
p.rich <- power.anova.test(groups = length(groupmeans),
between.var = var(groupmeans), within.var = 65.85873 ,
power=0.95,sig.level=0.05,n=NULL)
p.rich
groupmeans <- data.bac.plant$mean.rich
n.aov <- c(seq(2,10,by=1),seq(12,20,by=2),seq(25,50,by=5))
n.aov
p.rich <- power.anova.test(groups = length(groupmeans),
between.var = var(groupmeans), within.var = 65.85873,
power=NULL, sig.level=0.05,n=n.aov)
p.rich
p.rich.df <- data.frame(n=n, power=power)
plot(n.aov,p.rich$power)
set.seed(13)
nested.rich <- aov(bean.map$Richness~bean.map$Plant/factor(bean.map$Pod))
EtaSq(nested.rich, type=1, anova=TRUE)
EtaSq(fit.rich, type=1, anova=TRUE)
set.seed(13)
pwr.anova.test(k = 2, f =0.719, sig.level =0.05 , power =0.8 )
pwr.anova.test(k = 2, f =0.719, sig.level =0.05 , power =0.95 )
set.seed(13)
nested.rich <- aov(bean.map$Richness~bean.map$Plant/factor(bean.map$Pod))
nested.rich
EtaSq(nested.rich, type=1, anova=TRUE)
EtaSq(fit.rich, type=1, anova=TRUE)
set.seed(13)
nested.rich <- aov(bean.map$Richness~bean.map$Plant/factor(bean.map$Pod))
library(DescTools)
set.seed(13)
nested.rich <- aov(bean.map$Richness~bean.map$Plant/factor(bean.map$Pod))
nested.rich
EtaSq(nested.rich, type=1, anova=TRUE)
EtaSq(fit.rich, type=1, anova=TRUE)
summary(nested.rich)
pwr.anova.test(k = 2, f =0.719, sig.level =0.05 , power =0.8 )
groupmeans <- data.bac.plant$mean.rich
p.rich <- power.anova.test(groups = length(groupmeans),
between.var = var(groupmeans), within.var = 65.85873 ,
power=0.95,sig.level=0.05,n=NULL)
p.rich
pwr.anova.test(k = 2, f =0.719, sig.level =0.05 , power =0.8 )
p.rich
groupmeans <- data.bac.plant$mean.rich
n.aov <- c(seq(2,10,by=1),seq(12,20,by=2),seq(25,50,by=5))
p.rich <- power.anova.test(groups = length(groupmeans),
between.var = var(groupmeans), within.var = 65.85873,
power=NULL, sig.level=0.05,n=n.aov)
p.rich
p.rich.df <- data.frame(n=n, power=power)
plot(n.aov,p.rich$power)
#rarecurve
power.rich.plot
power.pd.plot
